<h1>Adventures in Graph Learning</h1>
<p>Or, <em>How I Maybe Missed Out on a Few Hundred Euros</em></p>
<p>A handful of months ago my MS program advisor dropped a link to IARAI's
<a href="https://github.com/iarai/science4cast">2021Science4Cast competition</a> in the
program's forums. The competition's task is to turn ML-soothesayer and predict
future connections between machine learning topics within publications (e.g.
will &quot;Deep Learning&quot; and &quot;Ordinary Differential Equations&quot; show up in the
same paper in the next three years?). I poked through the example solution,
which precomputed some metrics for each pair of topics in the training set
and fed them to a simple three-layer neural network and thought, &quot;I could beat
that, no problem!&quot;</p>
<p><em>Did</em> I beat that? Yes! Was it &quot;no problem&quot;? No!</p>
<h2>(Not) Everything's a Vision Problem</h2>
<p>It turns out I am a bit of a neural network one-trick pony.</p>
