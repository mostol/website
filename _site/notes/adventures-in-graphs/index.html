<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="/style.css">
  <!-- Grab title from the page data and dump it here -->
  <title>Adventures in Graphs, Part 1: (Not) Everything&#39;s a Vision Problem | Jackson Mostoller</title>
</head>
<body>
  <nav id="navbar">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/about/">About</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/notes/">Open Notes</a></li>
  </ul>
</nav>
  <!-- Grab the content from the page data and dump it here, and mark it as safe -->
  <!-- Safe docs: https://mozilla.github.io/nunjucks/templating.html#safe -->
  <p>This last year, IARAI ran a <a href="https://github.com/iarai/science4cast">2021 Science4Cast competition</a>, with the task of turning research-soothsayer and predicting what topics will be linked together through future machine learning research publications (e.g. will &quot;Deep Learning&quot; and &quot;Ordinary Differential Equations&quot; show up in the same paper in the next three years?). I poked through the <a href="https://github.com/iarai/science4cast/blob/main/Tutorial/tutorial.ipynb">example solution</a>, which precomputed some metrics for each pair of topics in the training set and fed them to a simple three-layer neural network and thought, &quot;I could beat that, no problem!&quot;</p>
<p>Did I beat it? Yep! Was it &quot;no problem&quot;? Nope! In fact, I attempted two completely different approaches, and one of them didn't even beat the tutorial solution provided as a straightforward example. And that's the one I'll describe here, because even if it wasn't successful, it was an interesting process! (To me, at least.) Here's how it went.</p>
<h2>Sight setting</h2>
<p>Since the end goal of the competition is to be able to take in two topics and predict whether or not they will connect in the future, the most intuitive approach to me seemed to be feeding a representation of each topic into a neural network, and training that network to classify the outcome for us.</p>
<p>I know that there's a neuropsychologically-rooted understanding of deep neural networks, but I am not a neuropsychologist, so my best intuitive grasp of how neural nets work is rooted in the <a href="https://wikipedia.org/wiki/Universal_approximation_theorem">Universal Approximation Theorem</a> and functions in their most basic form, which is &quot;you put a thing in, and you get a thing out&quot;. If we can clearly define what we're putting in and what we want to get out, then we can set up a model that takes thing <code>A</code> in and spits thing <code>B</code> out and let our training algorithms optimize that process ✨<em>mathemagically</em>✨ to do it with data it hasn't seen before. Thinking about a deep learning model this way, while maye not the most rigorous or complex approach, has the added benefit of letting me focus on single idea, which helps me avoid getting bogged down in less-important implementation details or do something that's accidentally incompatible with the competition task.</p>
<p>The details in between are flexible, but here was my mantra for this approach:</p>
<ol>
<li>The model must take take in representations of <em>two</em> nodes, and</li>
<li>The model must tell me, yes or no, <em>Will these two nodes be connected in 3 years?</em></li>
</ol>
<p>For the sake of flexibility, I decided that, while the competition expects me to predict results for three years from the present, that number shouldn't necessarily be baked in to the fundamental design of the model, so I dubbed this the &quot;n-Years Model&quot;, where <code>n = 3</code> in this case.</p>
<h2>Everything's a vision problem?</h2>
<p>So, how do we set up a model that takes in two node representations and spits out <em>the future</em>?</p>
<p>I could have sworn I remembered <a href="https://fast.ai">Jeremy Howard</a> saying something along the lines of, &quot;Almost anything can be treated as a computer vision problem.&quot; It turns out I can't find any record of that ever happening now, but there <em>is</em> a section highlighting how &quot;Image Recognizers Can Tackle Non-Image Tasks&quot; in the <a href="https://github.com/fastai/fastbook/blob/master/01_intro.ipynb">first chapter of fast.ai's <em>fastbook</em></a>. Either way, my first instinct was to convert the dataset into a computer vision problem by conjuring up some kind of image-based representation of the dataset, and then just using plain old image-classifying techniques to get it to make the right predictions. So the game plan is to feed the model an <em>image</em> representing two nodes, and have it classify whether or not they will be connected in three years.</p>
<h3>Step 1: Imagification</h3>
<p>The competition's tutorial solution relied on calculating the degree of each topic/node, as well as counting common neighbors shared with other nodes. This seemed like a reasonable approach, because with so little information, and no other context, each node is essentially <em>defined</em> by its neighbors—so it's not a bad idea to focus on those relationships.</p>
<p>Since each topic is semantically defined by its connections, can our image representation be pulled straight from a complete description of all of a node's relationships? Sure! For starters, we can convert our dataset into an <a href="https://en.wikipedia.org/wiki/Adjacency_list">adjacency list</a>, the sometimes less-popular but often more storage space-friendly sibling of the <a href="https://en.wikipedia.org/wiki/Adjacency_matrix">adjacency matrix</a>.</p>
<p>An adjacency list actually lends itself really well to creating images from its information, because images are really just arrays or tensors, and in PyTorch (<a href="https://numpy.org/doc/stable/user/basics.indexing.html#advanced-indexing">and NumPy</a>, where PyTorch got the idea from), tensors have &quot;fancy&quot; indexing of arrays using other arrays. Why is that handy? Because we can theoretically take a list of non-adjacent node id's, use them as the indices to select from another existing array, and set them to whatever value(s) we choose. In other words, if we have a node's adjacency list, we can use that directly as an index to represent that node's neighbors as <code>1</code> (or some other value) in a tensor, while leaving all other values <code>0</code>.</p>
<pre class="language-python"><code class="language-python">node0_neighbors <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># A made-up list of node 0's neighbor nodes.</span><br><br><span class="token comment"># Create a "base" of zeros</span><br>base <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">64000</span><span class="token punctuation">)</span> <span class="token comment"># Each of the 64000 nodes gets a spot.</span><br><br>base<span class="token punctuation">[</span>node0_neighbors<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># Now, all of node 0's neighbors are `1`, and everything else is 0.</span></code></pre>
<p>Getting a full-graph adjacency list to use for this isn't too hard, but there <em>is</em> one caveat: our list is going to need to retain information about not just node connectivity, but also time. Remember, our model is supposed to tell us whether two nodes will be connected in <em>n</em> years—so in order to provide the model with ground-truth data to train on, we need to know about nodes' connectivity three years from whatever we feed the model. We'll get to how we could incorporate that to use during training, but here's the creation of our adjacency list, making sure we retain the temporal info:</p>
<pre class="language-python"><code class="language-python"><span class="token comment"># Using the built-in `defaultdict` from Python's `collections`</span><br><span class="token comment"># lets us easily build a dict iteratively without having</span><br><span class="token comment"># to know the final state its elements from the start:</span><br><br><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict<br><br>adj_list <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span><br><br><span class="token comment"># The `graph` is just an array listing all of</span><br><span class="token comment"># the graph's edges, formatted as:</span><br><span class="token comment">#   node1 | node2 | time</span><br><br><span class="token keyword">for</span> edge <span class="token keyword">in</span> graph<span class="token punctuation">:</span><br>    n1<span class="token punctuation">,</span>n2<span class="token punctuation">,</span>t <span class="token operator">=</span> edge<br><br>    adj_list<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>n2<span class="token punctuation">,</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><br>    adj_list<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>n1<span class="token punctuation">,</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><br><br><span class="token comment"># To enable fancy indexing (and speed up other processes),</span><br><span class="token comment"># we'll turn these lists into arrays by way of tensors. A </span><br><span class="token comment"># little hacky? Yes. But it was the fastest method I could find! 😅</span><br><br><span class="token keyword">for</span> key<span class="token punctuation">,</span>value <span class="token keyword">in</span> arr_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    adj_list<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span></code></pre>
<p>Now, if we want to create an &quot;image&quot; for a node's connectivity, we can use the little process from above and get this:</p>
<pre class="language-python"><code class="language-python"><span class="token comment"># If there are ~64000 nodes, then 255 x 255 could be a big enough image size</span><br>image_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span><br><br>base <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>image_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><br><br><span class="token comment"># Generate the image for node 37</span><br>edges <span class="token operator">=</span> adj_list<span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># We have to index the 0th item: [0]: connected nodes, [1]: connection times</span><br>base<span class="token punctuation">[</span>edges<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># Set selected elements to 1</span><br><br><span class="token comment"># We'll even make it look image-y by making it a square shape:</span><br>image <span class="token operator">=</span> base<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span></code></pre>
<p>Neat! Now to deal with that <em>time</em> element. But wait…what's that? Something's derailing us—<strong>*A wild ambition appears!*</strong> 😮</p>
<h3>Tangent 1: <em>k</em>-hop neighbors</h3>
<p>You know what's (ostensibly) better than 1-hop neighborhoods at representing nodes and supplying substantial information to train on? <em>2-hop</em> neighborhoods! Right now, each of our images we feed to the model are poised to simply be basic representations of a node's immediate neighbors—but what if we also included the <em>neighbors of those neighbors</em> at a given point in time in our image? Wouldn't the sheer density and magnitude of additional relevant information—the unreasonable effectiveness of more data!—<em>blow the socks off</em> of the tutorial model?! 😱🤯 It turns out that it did not. But I went through the trouble of making 2nd order neighbors work, anyways, so here we are.</p>
<p>In theory, it shouldn't be too hard to get the second order neighbors for a node. We already have all of the neighbors in our adjacency list, so we can just index the adjacency list of each of a node's neighbors, and we're good! Here's a simple way to do that:</p>
<pre class="language-python"><code class="language-python">src_node <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># Finding node 1's 2nd order neighbors</span><br><br><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> neighbor <span class="token keyword">in</span> adj_list<span class="token punctuation">[</span>src_node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span></code></pre>
<p>That's great, but we're also going to need to use the temporal data from all of these neighbors—as noted above, we need to restrict our view of the graph to certain time constraints, which means we can't just index <em>every</em> neighbor. Instead, we'll want something more like this:</p>
<pre class="language-python"><code class="language-python">src_node <span class="token operator">=</span> <span class="token number">1</span><br>t <span class="token operator">=</span> <span class="token number">8000</span> <span class="token comment"># Set time cutoff to day 8000</span><br><br><span class="token comment"># The third indexing selector on each of these only indexes</span><br><span class="token comment"># the locations where the expression is `True`, i.e.</span><br><span class="token comment"># wherever the time array is less than `t`.</span><br><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> t<span class="token punctuation">]</span><br> <span class="token keyword">for</span> neighbor <span class="token keyword">in</span><br> adj_list<span class="token punctuation">[</span>src_node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>src_node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> t<span class="token punctuation">]</span><span class="token punctuation">]</span></code></pre>
<p>There is also a <a href="#altered-matrix-multiplication">much more convoluted way</a> of doing this that entails implementing an altered matrix multiplication for a sparsely-described adjacency matrix, leveraging the fact that <a href="https://arxiv.org/abs/1207.3122">the square of an adjacency matrix represents the number of walks of length two from one node to another</a>. I originally opted for this approach out of fear that Python's iteration would be too slow with the method above for practical use during training, but after testing it out while writing this post…the above list comprehension is actually faster. Here's my final function to get a node's first and second order neighbors (with built-in functionality for getting up to <em>k</em> total layers of neighbors, although exponential list growth with this approach makes any <em>k</em> &gt; 2 a bit problematic):</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_neighbors</span><span class="token punctuation">(</span>adj_list<span class="token punctuation">,</span> node<span class="token punctuation">,</span> t<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    neighbors_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><br>    nbrs <span class="token operator">=</span> <span class="token punctuation">[</span>node<span class="token punctuation">]</span><br>    <span class="token keyword">if</span> t <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span><br>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span><br>            <span class="token comment"># If our node *has* no neighbors, we'll get an error we need to handle.</span><br>            <span class="token keyword">try</span><span class="token punctuation">:</span><br>                nbrs <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> node <span class="token keyword">in</span> nbrs<span class="token punctuation">]</span><span class="token punctuation">)</span><br>            <span class="token keyword">except</span> <span class="token punctuation">(</span>IndexError<span class="token punctuation">,</span> ValueError<span class="token punctuation">)</span><span class="token punctuation">:</span><br>                nbrs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><br><br>            neighbors_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nbrs<span class="token punctuation">)</span><br>    <span class="token keyword">else</span><span class="token punctuation">:</span><br>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span><br>            <span class="token keyword">try</span><span class="token punctuation">:</span><br>                nbrs <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>adj_list<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> t<span class="token punctuation">]</span><br>                                       <span class="token keyword">for</span> node <span class="token keyword">in</span> nbrs<span class="token punctuation">]</span><span class="token punctuation">)</span><br>            <span class="token keyword">except</span> <span class="token punctuation">(</span>IndexError<span class="token punctuation">,</span> ValueError<span class="token punctuation">)</span><span class="token punctuation">:</span><br>                nbrs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><br><br>            neighbors_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nbrs<span class="token punctuation">)</span><br><br>    <span class="token keyword">return</span> neighbors_list</code></pre>
<p>This returns a list of first order neighbors, followed by second neighbors (and up to <em>k</em>th order neighbors if we really wanted).</p>
<h3>Step 2: Temporal label-wrangling</h3>
<p>If you think about it, we don't really even need <em>any</em> information about the time that previous connections were made when we're doing predictions; it ought to be enough to know the connectivity of each node right now and whip up an image. But if we remember the second pillar of my model mantra:</p>
<blockquote>
<p>The model must tell me, yes or no, <em>Will these two nodes be connected in 3 years?</em></p>
</blockquote>
<p>in order to train the model, we're going to need to pass the model node representations and also <em>tell</em> it if those nodes happened to get connected within 3 years, so that it has enough context to actually answer the question.</p>
<p>In order to have lots of possible samples to train off of, it seems like a good idea to be able to pass the model <em>any</em> two nodes at <em>any</em> given point in time, and to get a yes/no as to whether they will be linked in three years. I found it easiest to think about this in terms of &quot;do these nodes connect at any point at all?&quot; and then handle the timing part appropriately after figuring that out—this way, we can maximize the number of actual connections we feed the model so that training is more balanced, instead of feeding it nodes-that-won't-connect 99.8% of the time. There are a few possibilities here:</p>
<ol>
<li>One (or both) of the nodes has <em>no</em> connections at the given time. A blank slate is not particularly meaningful here, so it might be best to just avoid or ignore this case.</li>
<li>The nodes both have neighbors, but they <em>never</em> connect to one another. In this case, any time point is as good as another, so we can pick whichever one we want to feed the model. <strong>BUT!</strong> We have to be careful about the maximum timestamp we're willing to offer. If I feed the model two nodes as they exist on January 1, 2017, but my data only goes as far as 2019, then I know that they haven't been linked <em>yet</em>, but I <em>do not know</em> if they will connect within 3 years because it hasn't <em>been</em> three years yet. So in this case, we can input the nodes as they are at any date, <em>as long as</em> that date is beyond <em>n</em> years of our most up-to-date data.</li>
<li>The nodes do connect at some point. Keeping in mind that we want to maximize our already-scarce supply of positive samples, we probably want to make sure we pick a date that puts these cases to good use. If two topics are linked in March 2009, for example, I don't want to give the model their representations as they exist in April 2003, because based on the April 2003 images, the answer to the question, <em>Will these two nodes be connected in 3 years?</em> is <code>no</code>. This is why focusing on connection status over dates is handy—in these instances, we can make sure we pass representations that are within <em>n</em> years of connection into our model for training so we have as many positive samples as possible.</li>
</ol>
<p>With all that forethought out of the way, we can dive into setting up and training the model!</p>
<h2>Transforms &amp; training</h2>
<p>For training, I used fast.ai, leveraging its <a href="https://docs.fast.ai/tutorial.siamese.html#Using-the-mid-level-API">mid-level API</a> to work nicely with the above conditions. I decided that, from a user standpoint, the most ideal and intuitive way to interact with the model would be to simply pass in two node id's and let the model either train on that info or predict on in. Here's how we can make that happen with fast.ai's <a href="https://fastcore.fast.ai/transform#Transform"><code>Transform</code></a>s.</p>
<p>A <code>Transform</code> is, at the most basic level, just a function: it takes an input and <em>transforms</em> it into something else. (You might say a <code>Transform</code> is a <em>function in disguise</em>.) They have some nifty bonus features—like type dispatch, potential reversability (to allow both encoding and <em>de</em>coding), and extensability to name a few—but my primary use here is to use them as a medium for creating fast.ai <code>DataBlock</code>s in a convenient format for my partucular data. There are quite a few ways to define a <code>Transform</code>, but I opted for simply extending the <code>Transform</code> class. That looks like this:</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SomeKindOfTransform</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">pass</span></code></pre>
<p>But for it do actually do anything, we need the <code>Transform</code> to have an <code>encodes</code> method; so a transform that simply squares its input might look something like this:</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SquareTransform</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token keyword">def</span> <span class="token function">encodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token keyword">return</span> x<span class="token operator">**</span><span class="token number">2</span><br><br>SquareTransform<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span> <span class="token comment"># Gives us 144.</span></code></pre>
<h3>Defining <code>NYearsTransform</code></h3>
<p>Alright! Now to define a <code>Transform</code> to accept two nodes and return an image representation of them based on their neighbors. First, we can to prepare all of the logic to handle the situations outlined above.</p>
<h4>Initialization, contextual settings, utilities</h4>
<p>Our <code>Transform</code> is going to need some background information for every transformation it does; things like:</p>
<ul>
<li>What are the dimensions of the final image?</li>
<li>What adjacency list are we pulling our information from?</li>
<li>How big is the <em>n</em> in &quot;<em>n</em> years,&quot; actually?</li>
</ul>
<p>as well as other utilities that may be used repeatedly in the transformation process. We'll these up to be incorporated when we initialize a <code>NYearsTransform</code> object using the <code>__init__</code> function:</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NYearsTransform</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span><br><br>    <span class="token comment"># Initialization</span><br>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adj_list<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> img_shape<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>        self<span class="token punctuation">.</span>adj_list <span class="token operator">=</span> adj_list <span class="token comment"># Attach an inputted adjacency list to the object</span><br>        <span class="token keyword">if</span> mode <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'eval'</span><span class="token punctuation">}</span><span class="token punctuation">:</span> <span class="token comment">#Specify a mode ("train" or "eval"). We'll get to this in a moment!</span><br>            self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode<br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'`mode` should be `"train"` or `"eval"`'</span><span class="token punctuation">)</span><br><br>        <span class="token comment"># Time-related attributes</span><br>        self<span class="token punctuation">.</span>t_delta <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token number">365</span> <span class="token comment"># Graph times are in days, so we need to have "n years" in terms of days</span><br><br><br>        <span class="token comment">### Latest time on the graph. (Avoids checking nodes with no connections.)</span><br>        max_graph_time <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> edges <span class="token keyword">in</span> adj_list<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">)</span><br><br>        <span class="token comment">### For training, only edges formed `n` years before the latest data are "True" values for certain:</span><br>        self<span class="token punctuation">.</span>t_cutoff <span class="token operator">=</span> max_graph_time <span class="token operator">-</span> self<span class="token punctuation">.</span>t_delta<br><br>        <span class="token comment"># Image-making attributes</span><br>        <span class="token comment">### If you manually define a shape, set that as the shape...</span><br>        <span class="token keyword">if</span> img_shape <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> shape <br>        <span class="token comment">### Otherwise, image is the smallest square possible based on number of nodes</span><br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            len_sqrt <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>adj_list<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>len_sqrt<span class="token punctuation">,</span> len_sqrt<span class="token punctuation">)</span><br></code></pre>
<p>One important operation we'll need every time we use our transform is converting our list of neighboring nodes to an image, as <a href="#something-something">mentioned previously</a>. We can convert the same approach into a function and add it as a built-in part of our class:</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NYearsTransform</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adj_list<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> img_shape<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>        self<span class="token punctuation">.</span>adj_list <span class="token operator">=</span> adj_list<br>        <span class="token keyword">if</span> mode <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'eval'</span><span class="token punctuation">}</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode<br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'`mode` should be `"train"` or `"eval"`'</span><span class="token punctuation">)</span><br><br>        self<span class="token punctuation">.</span>t_delta <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token number">365</span><br><br>        max_graph_time <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> edges <span class="token keyword">in</span> adj_list<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span>t_cutoff <span class="token operator">=</span> max_graph_time <span class="token operator">-</span> self<span class="token punctuation">.</span>t_delta<br><br>        <span class="token keyword">if</span> img_shape <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> shape <br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            len_sqrt <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>adj_list<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>len_sqrt<span class="token punctuation">,</span> len_sqrt<span class="token punctuation">)</span><br><br>    <span class="token comment"># *NEW* Adding a utility function to turn list of neighbors to image tensors.</span><br>    <span class="token keyword">def</span> <span class="token function">get_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        base <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><br>        base<span class="token punctuation">[</span>edges<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><br>        <span class="token keyword">return</span> TensorImage<span class="token punctuation">(</span>base<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span></code></pre>
<h4>Training vs. evaluation modes</h4>
<p>If you read my <a href="#Step-2">earlier exposition</a> carefully, you may have caught wind of the subtle intimation that we're going to need to do fairly different things during training vs. inference. To deal with this I decide to set the <code>Transform</code> up to handle two disting &quot;modes&quot;: <code>'train'</code>, where we carefully supply timeframes and contexts that are useful for training, and <code>'eval'</code>, where we just grab the most up-to-date connectivity information and go. I decided to just have the mode be determined by passing in a string.</p>
<p>This is where we finally get to define the full behavior of the <code>Transform</code>! This is done with the associated <code>encodes</code> function. It will take in a pair of nodes (a <code>nodepair</code>) and, based on the mode, return the appropriate image. If we're in &quot;Train&quot; mode, the transform will return not just the image, but also the label correctly answering the question, <em>Will these two nodes be connected in <em>n</em> years?</em></p>
<p>One bonus aspect we might want to consider is differentiating 1st and 2nd order neighbors in our image. It may be useful for the model to distinguish between those when trying to make a prediction. One way we could handle this is by having a (2 * <em>k</em>)-channel image; in other words, each set of <em>k</em>th order neighbors gets its own layer for each node. But this might make visualization a bit tricky (if we want to actually look at the &quot;images&quot;), because most libraries expect an image to either be 1-channel or 3-channel, and it also means larger tensors are getting passed in. Another option would be summing layers together in a way that retains the seperability of the information at the end, which is the approach I opted for. For example, if we weight first order neighbors as <code>0.75</code> and second order neighbors as <code>0.25</code>, then we can tell that a node with <code>0</code> had no connections, a node with <code>0.75</code> was exclusively a first order neighbor, one with <code>0.25</code> is exclusively a second order neighbor, and <code>1.0</code> is a node that is connected by both one <em>and</em> two hops. Here's the final implementation of the <code>Transform</code> including summed-and-weighted neighbor layers and both transform modes.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NYearsTransform</span><span class="token punctuation">(</span>Transform<span class="token punctuation">)</span><span class="token punctuation">:</span><br><br>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adj_list<span class="token punctuation">,</span> mode<span class="token punctuation">,</span> img_shape<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>        self<span class="token punctuation">.</span>adj_list <span class="token operator">=</span> adj_list<br>        <span class="token keyword">if</span> mode <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'eval'</span><span class="token punctuation">}</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode <span class="token comment"># Told you we'd get there!</span><br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'`mode` should be `"train"` or `"eval"`'</span><span class="token punctuation">)</span><br><br>        self<span class="token punctuation">.</span>t_delta <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token number">365</span><br><br>        max_graph_time <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> edges <span class="token keyword">in</span> adj_list<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span>t_cutoff <span class="token operator">=</span> max_graph_time <span class="token operator">-</span> self<span class="token punctuation">.</span>t_delta<br><br>        <span class="token keyword">if</span> img_shape <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> shape <br>        <span class="token keyword">else</span><span class="token punctuation">:</span><br>            len_sqrt <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>adj_list<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><br>            self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>len_sqrt<span class="token punctuation">,</span> len_sqrt<span class="token punctuation">)</span><br><br>        <span class="token comment"># *NEW* Adding in weighting for 1st and 2nd order neighbors.</span><br>        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">)</span><br><br>    <span class="token comment"># *NEW* Defining our encodes!</span><br>    <span class="token keyword">def</span> <span class="token function">encodes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nodepair<span class="token punctuation">:</span>Iterable<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        nodepair <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token builtin">int</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> nodepair<span class="token punctuation">}</span><br><br>        <span class="token comment">### EVAL ### (Returns just a TensorImage)</span><br>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'eval'</span><span class="token punctuation">:</span><br>            <span class="token comment"># Create, weigh, and sum layers for each node</span><br>            img_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>get_img<span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token operator">*</span>weight<br>                              <span class="token keyword">for</span> layer<span class="token punctuation">,</span>weight<br>                              <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>get_neighbors<span class="token punctuation">(</span>self<span class="token punctuation">.</span>adj_list<span class="token punctuation">,</span>n<span class="token punctuation">)</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><br>                          <span class="token keyword">for</span> n <span class="token keyword">in</span> nodepair<span class="token punctuation">]</span><br><br>            <span class="token comment"># Return stacked representation of nodes.</span><br>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>img_layers<span class="token punctuation">)</span><br><br>        <span class="token comment">### TRAIN ### (Train mode will return the TensorImage *and* a label.)</span><br>        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span><br>            <span class="token comment"># To check for connectivity, we need to look at nodes individually for a sec.</span><br>            nodes_copy <span class="token operator">=</span> nodepair<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><br>            link_list <span class="token operator">=</span> arr_dict<span class="token punctuation">[</span>nodes_copy<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><br>            partner_node <span class="token operator">=</span> nodes_copy<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><br>            linked <span class="token operator">=</span> partner_node <span class="token keyword">in</span> link_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># A boolean value</span><br><br>            <span class="token comment"># If nodes connect</span><br>            <span class="token keyword">if</span> linked<span class="token punctuation">:</span><br>                lim <span class="token operator">=</span> link_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>link_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> partner_node<span class="token punctuation">]</span> <span class="token comment"># Time of the connection</span><br><br>                <span class="token comment"># Passing that time into `get_neighbors` gets all connections *before* that point</span><br>                img_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>get_img<span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token operator">*</span>weight<br>                                  <span class="token keyword">for</span> layer<span class="token punctuation">,</span>weight<br>                                  <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>get_neighbors<span class="token punctuation">(</span>self<span class="token punctuation">.</span>adj_list<span class="token punctuation">,</span>n<span class="token punctuation">,</span>lim<span class="token punctuation">)</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><br>                              <span class="token keyword">for</span> n <span class="token keyword">in</span> nodepair<span class="token punctuation">]</span><br><br>                <span class="token comment"># If either edgelist is empty at this time (i.e. this is >= 1 node's first link ever)</span><br>                <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>layer<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">for</span> layer <span class="token keyword">in</span> img_layers<span class="token punctuation">)</span><span class="token punctuation">:</span><br>                    label <span class="token operator">=</span> <span class="token number">0</span><br><br>                <span class="token comment"># Otherwise (normal behavior):</span><br>                <span class="token keyword">else</span><span class="token punctuation">:</span><br>                    partner_links <span class="token operator">=</span> arr_dict<span class="token punctuation">[</span>partner_node<span class="token punctuation">]</span><br><br>                    <span class="token comment"># Most recent link time before these two nodes linked:</span><br>                    maxlink <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>link_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>link_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> lim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                      np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>partner_links<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>partner_links<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> lim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>                    <span class="token comment"># Verify previous link (image reference) and most recent link are actually within n years.</span><br>                    label <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">if</span> lim <span class="token operator">-</span> maxlink <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>t_delta <span class="token keyword">else</span> <span class="token number">0</span><br><br>            <span class="token comment"># If nodes do not connect</span><br>            <span class="token keyword">else</span><span class="token punctuation">:</span><br>                <span class="token comment"># Get connections as they are at `self.t_cutoff` </span><br>                <span class="token comment"># (any later and we aren't *really* sure they won't connect in n years</span><br>                img_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>get_img<span class="token punctuation">(</span>layer<span class="token punctuation">)</span><span class="token operator">*</span>weight<br>                                  <span class="token keyword">for</span> layer<span class="token punctuation">,</span>weight<br>                                  <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>get_neighbors<span class="token punctuation">(</span>self<span class="token punctuation">.</span>adj_list<span class="token punctuation">,</span>n<span class="token punctuation">,</span>self<span class="token punctuation">.</span>t_cutoff<span class="token punctuation">)</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><br>                              <span class="token keyword">for</span> n <span class="token keyword">in</span> nodepair<span class="token punctuation">]</span><br><br>                label <span class="token operator">=</span> <span class="token number">0</span><br><br>            <span class="token comment"># Return image,label</span><br>            <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>img_layers<span class="token punctuation">)</span><span class="token punctuation">,</span>label<br><br>    <span class="token keyword">def</span> <span class="token function">get_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        base <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><br>        base<span class="token punctuation">[</span>edges<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><br>        <span class="token keyword">return</span> TensorImage<span class="token punctuation">(</span>base<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span></code></pre>
<p>Now that our transform is ready to go, we can flesh out the training pipeline, and get training!.</p>
<h3>Training pipeline</h3>
<p>So we have a <code>Transform</code> that converts to topics into image representations of those topics based on their connectivity, and will also provide a label telling us whether those images represent two graphs that will be connected in <em>n</em> years. But how do we use that to create a model? All we have to do is pass in a bunch of node pairs to the transform, and then pass the output of the transform (the image and label) to a vision model, and train!</p>
<p>Fast.ai uses <a href="#link-to-datablock-api">&quot;datablocks&quot;</a> for training—objects containing either the data and labels themselves, or a way to <em>get</em> the data and labels. While we don't have a built-in <code>DataBlock</code> that's fit to use with our current setup, we can make training and validation <code>DataBlock</code>s fairly simply from our <code>Transform</code>. The built-in <code>ImageBlock</code>, for example, takes in strings indicating image file paths and labels, uses those to get the actual images/labels, and passes those to the model—but doesn't actually store the images themselves <em>in</em> the datablock. We'll do something similar, but instead of getting images from a file, we're generating them based on simply inputting two node id's. Since we've built our own custom <code>Transform</code> that's not dependent upon an existing type of <code>DataBlock</code>, we'll use a <a href="https://docs.fast.ai/data.core.html#TfmdLists"><code>TfmdList</code></a> (&quot;Transformed List&quot;) instead of an actual <code>DataBlock</code> object, but they're fundamentally the same: take in information and transform it on-the-fly into the format needed for training. But before we make a <code>TfmdList</code>, we'll need to select pairs of nodes we want to use for training and for validation.</p>
<h4>Training and validation sets</h4>
<p>We could use a much larger training set, but to keep training time down, I'll start with something a bit more modest. Let's say…5000 samples? We could select 5000 random combinations of nodes for our training set, but remember that the dataset is <em>incredibly</em> sparse—so if we just pick node pairs as random, we'll end up with a <em>lot</em> of &quot;these topics do not connect&quot;, so the point where training might not even accomplish anything and the model may just assume that the correct label is always 0. A better idea is to try to intentionally balance our training set so that it has roughly equal amounts of positive and negative samples; cases where we know for sure that the nodes will connect, along with cases where they won't. So let's split our training set up into equal &quot;positive&quot; and &quot;negative&quot; groups—the <code>TfmdList</code> will want these as lists, so we'll also make sure our sample node pairs are in that format:</p>
<pre class="language-python"><code class="language-python">pos_size <span class="token operator">=</span> <span class="token number">2500</span><br>neg_size <span class="token operator">=</span> <span class="token number">2500</span><br><br><span class="token comment"># Set up some random number generation in NumPy (with seed = 42)</span><br>rng <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>default_rng<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span><br><br>pos_size <span class="token operator">=</span> <span class="token number">2500</span><br>neg_size <span class="token operator">=</span> <span class="token number">2500</span><br><br>pos_sel <span class="token operator">=</span> rng<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>graph<span class="token punctuation">)</span><span class="token punctuation">,</span>pos_size<span class="token punctuation">,</span>replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><br>neg_sel <span class="token operator">=</span> rng<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>unconnected_v_pairs<span class="token punctuation">)</span><span class="token punctuation">,</span>neg_size<span class="token punctuation">,</span>replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><br><br><span class="token comment"># Grab 2500 pairs that already exist from the graph (w/o time column)</span><br>pos_sample <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>graph<span class="token punctuation">[</span>pos_sel<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><br><span class="token comment"># Pull 2500 pairs from the `unconnected_v_list`, all of which are unconnected at this point</span><br>neg_sample <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>unconnected_v_pairs<span class="token punctuation">[</span>neg_sel<span class="token punctuation">]</span><span class="token punctuation">)</span> </code></pre>
<p>We'll also want to split up our samples so we have a both a training <em>and</em> a validation set. If we take the samples we've already generated (instead of generating more), we'll make sure we don't accidentally end up with duplicated pairs in both our training and validation sets (which would kind of defeat the purpose of having a validation set in the first place).</p>
<pre class="language-python"><code class="language-python">split <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">2500</span><span class="token operator">*</span><span class="token number">0.2</span><span class="token punctuation">)</span> <span class="token comment"># Pick an index to split at</span><br><br>pos_train<span class="token punctuation">,</span> pos_valid <span class="token operator">=</span> pos_sample<span class="token punctuation">[</span><span class="token punctuation">:</span>split<span class="token punctuation">]</span><span class="token punctuation">,</span>pos_sample<span class="token punctuation">[</span>split<span class="token punctuation">:</span><span class="token punctuation">]</span><br>neg_train<span class="token punctuation">,</span> neg_valid <span class="token operator">=</span> neg_sample<span class="token punctuation">[</span><span class="token punctuation">:</span>split<span class="token punctuation">]</span><span class="token punctuation">,</span>neg_sample<span class="token punctuation">[</span>split<span class="token punctuation">:</span><span class="token punctuation">]</span><br><br>train_list <span class="token operator">=</span> pos_train <span class="token operator">+</span> neg_train<br>valid_list <span class="token operator">=</span> pos_valid <span class="token operator">+</span> neg_valid</code></pre>
<h4>Transformed Lists, DataLoaders</h4>
<p>Now to turn the samples into <code>TfmdLists</code>, with the correct transform behavior depending on if we're training or validating:</p>
<pre class="language-python"><code class="language-python">train_tl <span class="token operator">=</span> TfmdLists<span class="token punctuation">(</span>train_list<span class="token punctuation">,</span> NYearsTransform<span class="token punctuation">(</span>arr_dict<span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span>n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br>valid_tl <span class="token operator">=</span> TfmdLists<span class="token punctuation">(</span>valid_list<span class="token punctuation">,</span> NYearsTransform<span class="token punctuation">(</span>arr_dict<span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'eval'</span><span class="token punctuation">,</span>n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>Not a long step 😁</p>
<p>Now that we have our transformed lists, they function just like a fast.ai <code>Dataset</code> object, which means we can actually pass them straight into a <code>DataLoaders</code> and get training!</p>
<pre class="language-python"><code class="language-python">dls <span class="token operator">=</span> DataLoaders<span class="token punctuation">.</span>from_dsets<span class="token punctuation">(</span>train_tl<span class="token punctuation">,</span> valid_tl<span class="token punctuation">)</span><br>dls <span class="token operator">=</span> dls<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># If you're using a GPU (probably a good idea)</span></code></pre>
<h2>Training</h2>
<p>With all of that setup done, we can create our model/learner, give it some metrics, and let it rip! The competition's performance metric is ROC AUC, so it might be handy to use that as a metric while training. Fast.ai has this as a built-in metric already, so we can just initialize it and add it straight in to our learner:</p>
<pre class="language-python"><code class="language-python">roc_auc <span class="token operator">=</span> RocAucBinary<span class="token punctuation">(</span><span class="token punctuation">)</span><br>graph_learner <span class="token operator">=</span> cnn_learner<span class="token punctuation">(</span>dls<span class="token punctuation">,</span><br>                            xse_resnext18<span class="token punctuation">,</span> <span class="token comment"># You could slot in any vision model here and compare performance. I picked `xse_resnext18` at the time.</span><br>                            metrics<span class="token operator">=</span><span class="token punctuation">[</span>roc_auc<span class="token punctuation">,</span>accuracy<span class="token punctuation">]</span><span class="token punctuation">,</span><br>                            pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span><br>                            n_in<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>n_out<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># We have two "channels" (one for each node's image) to pass in, hence n_in=2. And it's binary classification, so n_out=2 also.</span><br>                            loss_func<span class="token operator">=</span>CrossEntropyLossFlat<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>And now, we train!</p>
<pre class="language-python"><code class="language-python">graph_learner<span class="token punctuation">.</span>fit_one_cycle<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment"># Train for 5 epochs.</span></code></pre>
<h2>Results; or, not everything is a vision problem.</h2>
<p>For brevity, I'll spare you the play-by-play process of validating the model against the solution set provided. The real question is, how did it do? At the end of training, the final ROC AUC score was...</p>
<pre><code>ROC_AUC: 0.7305075966006858
</code></pre>
<p>which is quite a bit lower than the tutorial solution's performance.</p>
<p>But that's okay! Not every approach is going to work for any given problem, and I got to dig a lot deeper into the fast.ai framework in the process of bringing the idea to fruition. Looking back over the setup and execution, I can also see some potential areas of improvement that might bring the model up to a more competitive level.</p>

</body>
</html>